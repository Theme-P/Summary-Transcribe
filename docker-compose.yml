services:
  whisperx:
    build: .
    container_name: Transummary
    stdin_open: true
    tty: true
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - HF_HOME=/app/.cache/huggingface
      - TORCH_HOME=/app/.cache/torch
    volumes:
      - ./audio:/app/audio
      # Persist model cache between container restarts
      - whisperx_cache:/app/.cache
    ports:
      - "8000:8000"
    env_file:
      - .env
    command: uvicorn api:app --host 0.0.0.0 --port 8000

volumes:
  whisperx_cache:
